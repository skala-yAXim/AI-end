# agents/git_analyzer.py
import os
import sys
import json
import pandas as pd
from typing import List, Dict, Optional, Any

from qdrant_client import QdrantClient
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import JsonOutputParser
from langchain.prompts import PromptTemplate

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from core import config
from core.state_definition import LangGraphState
from tools.vector_db_retriever import retrieve_git_activities

class GitAnalyzerAgent:
    def __init__(self, qdrant_client: QdrantClient):
        self.qdrant_client = qdrant_client
        
        self.llm_client = ChatOpenAI(
            model=config.DEFAULT_MODEL, temperature=0.1,
            openai_api_key=config.OPENAI_API_KEY, max_tokens=2500
        )
        # self.wbs_data_handler ì œê±°

        prompt_file_path = os.path.join(config.PROMPTS_BASE_DIR, "git_analyze_prompt.md")
        try:
            with open(prompt_file_path, 'r', encoding='utf-8') as f: 
                prompt_template_str = f.read()
            # ì˜ˆìƒ í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜: {author_identifier}, {wbs_assignee_name}, {target_date_str}, {git_info_str_for_llm}, {wbs_tasks_str_for_llm}
            self.prompt = PromptTemplate.from_template(prompt_template_str)
        except FileNotFoundError:
            print(f"GitAnalyzerAgent: ì˜¤ë¥˜ - í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {prompt_file_path}")
            self.prompt_template_str = """
ì‚¬ìš©ìž ì‹ë³„ìž {author_identifier} (WBS ë‹´ë‹¹ìžëª…: {wbs_assignee_name})ì˜ ëª¨ë“  ë ˆí¬ì§€í† ë¦¬ì— ëŒ€í•œ Git í™œë™({git_info_str_for_llm})ì„ {target_date_str} ê¸°ì¤€ìœ¼ë¡œ ë¶„ì„í•˜ê³ , 
ê´€ë ¨ WBS ìž‘ì—…({wbs_tasks_str_for_llm})ê³¼ì˜ ì—°ê´€ì„±ì„ íŒŒì•…í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„¸ ë¦¬í¬íŠ¸ë¥¼ ìž‘ì„±í•´ì£¼ì„¸ìš”. 
ë¦¬í¬íŠ¸ì—ëŠ” ì£¼ìš” í™œë™ ìš”ì•½, WBS ë§¤ì¹­ëœ ìž‘ì—…, ë§¤ì¹­ë˜ì§€ ì•Šì€ ìž‘ì—…, í• ë‹¹ë˜ì§€ ì•Šì€ Git í™œë™ ëª©ë¡ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
"""
            self.prompt = PromptTemplate.from_template(self.prompt_template_str)
        
        self.parser = JsonOutputParser()

    def _calculate_git_stats(self, retrieved_activities: List[Dict]) -> Dict[str, Any]:
        """
        ê²€ìƒ‰ëœ Git í™œë™ ëª©ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ í†µê³„ ì •ë³´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        """
        if not retrieved_activities:
            return {
                "total_commits": 0,
                "commit_by_hour": {},
                "summary_str": "ë¶„ì„í•  Git í™œë™ì´ ì—†ìŠµë‹ˆë‹¤."
            }

        commit_payloads = []
        for act in retrieved_activities:
            payload = act.get("metadata") # LangChain Qdrant RetrieverëŠ” payloadë¥¼ 'metadata'ì— ë‹´ì•„ì¤ë‹ˆë‹¤.
            if payload and payload.get("type") == "commit" and "date" in payload:
                commit_payloads.append(payload)

        if not commit_payloads:
            return {
                "total_commits": 0,
                "commit_by_hour": {},
                "summary_str": "ë¶„ì„í•  ì»¤ë°‹(commit) í™œë™ì´ ì—†ìŠµë‹ˆë‹¤."
            }

        # í•„í„°ë§ëœ ì»¤ë°‹ íŽ˜ì´ë¡œë“œë¡œ DataFrame ìƒì„±
        df = pd.DataFrame(commit_payloads)
        # ì´ë¯¸ì§€ì—ì„œ í™•ì¸ëœ 'date' í•„ë“œ(ISO 8601 í˜•ì‹)ë¥¼ datetime ê°ì²´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        df['date'] = pd.to_datetime(df['date'])

        total_commits = len(df)
        
        # ì‹œê°„ëŒ€ë³„ ì»¤ë°‹ ë¹ˆë„ ê³„ì‚° (0-23ì‹œ)
        # .dt accessorëŠ” Seriesì˜ ê° ê°’ì´ datetime ê°ì²´ì¼ ë•Œ ì‚¬ìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.
        commit_by_hour = df['date'].dt.hour.value_counts().sort_index().to_dict()
        
        # LLMì—ê²Œ ì „ë‹¬í•  ìš”ì•½ ë¬¸ìžì—´ ìƒì„±
        summary_parts = [f"### Git í™œë™ í†µê³„ ë¶„ì„\n- ì´ ì»¤ë°‹(PushEvent) ìˆ˜: {total_commits}ê±´"]
        if commit_by_hour:
            summary_parts.append("- ì‹œê°„ëŒ€ë³„ ì»¤ë°‹ ë¶„í¬:")
            # 0ì‹œë¶€í„° 23ì‹œê¹Œì§€ ëª¨ë“  ì‹œê°„ì— ëŒ€í•´ ì¶œë ¥ (ì—†ëŠ” ì‹œê°„ì€ 0ê±´)
            for hour in range(24):
                count = commit_by_hour.get(hour, 0)
                if count > 0:
                    summary_parts.append(f"  - {hour:02d}ì‹œ: {count}ê±´")
        
        summary_str = "\n".join(summary_parts)

        return {
            "total_commits": total_commits,
            "commit_by_hour": commit_by_hour,
            "summary_str": summary_str
        }



    def _prepare_git_data_for_llm(self, retrieved_git_activities: List[Dict], target_date_str: Optional[str]) -> str:
        date_info = f"({target_date_str} ê¸°ì¤€)" if target_date_str else "(ìµœê·¼ í™œë™ ê¸°ì¤€)"
        display_count = min(len(retrieved_git_activities), 30)  # ìµœëŒ€ 30ê±´ë§Œ ì¶œë ¥

        parts = [f"### ì „ì²´ Git í™œë™ ìš”ì•½ {date_info} (ìµœëŒ€ {display_count}ê±´):"]

        if display_count == 0:
            parts.append("í™œë™ ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
            return "\n".join(parts)

        for item in retrieved_git_activities[:display_count]:
            meta = item.get("metadata", {})
            repo = meta.get("repo_name", "N/A")
            sha_or_id = meta.get("sha", meta.get("id", "N/A"))[:7]
            author = meta.get("author", "N/A")
            event_date = meta.get("date", "N/A")
            event_type = meta.get("type", "N/A")
            message = item.get("page_content", meta.get("message", "N/A"))[:300]

            parts.append(f"- [{event_type}] ë ˆí¬: {repo}, ID: {sha_or_id} (ìž‘ì„±ìž: {author}, ë‚ ì§œ: {event_date})")
            parts.append(f"  ë©”ì‹œì§€: {message}")

        return "\n".join(parts)


    def _analyze_git_internal(
    self, 
    user_id: str, # Teams ë¶„ì„ ëŒ€ìƒ user_id
    user_name: Optional[str], # LLM í”„ë¡¬í”„íŠ¸ìš© user_name 
    target_date: str, # target_dateëŠ” í•„ìˆ˜
    wbs_data: Optional[dict],
    retrieved_activities: List[Dict],
    readme_info: str = ""
    ) -> Dict[str, Any]:
        total_count = len(retrieved_activities)
        print(f"GitAnalyzerAgent: ì‚¬ìš©ìž ì‹ë³„ìž '{user_id}' Git í™œë™ ë¶„ì„. ì´ {total_count}ê±´ (ëŒ€ìƒì¼: {target_date}).")
        
        if total_count == 0:
            print(f"GitAnalyzerAgent: ì‚¬ìš©ìž ì‹ë³„ìž '{user_id}'ì— ëŒ€í•œ ë¶„ì„í•  Git í™œë™ì´ ì—†ìŠµë‹ˆë‹¤ (ëŒ€ìƒì¼: {target_date}).")
            return {
                "summary": "ë¶„ì„í•  ê´€ë ¨ Git í™œë™ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
                "matched_tasks": [],
                "unmatched_tasks": [],
                "unassigned_git_activities": [],
                "error": "No Git activities to analyze"
            }
        # 1. Pythonìœ¼ë¡œ Git í™œë™ í†µê³„ ì‚¬ì „ ë¶„ì„
        git_stats = self._calculate_git_stats(retrieved_activities)
        git_stats_str = git_stats["summary_str"]

        wbs_data_str = json.dumps(wbs_data, ensure_ascii=False, indent=2) if wbs_data else "WBS ì •ë³´ ì—†ìŒ"
        git_data_str = self._prepare_git_data_for_llm(retrieved_activities, target_date)

        chain = self.prompt | self.llm_client | self.parser

        try:
            llm_input = {
                "author_email": user_id,
                "wbs_assignee_name": user_name or user_id,
                "target_date_str": target_date,
                "git_info_str_for_llm": git_data_str,
                "wbs_tasks_str_for_llm": wbs_data_str,
                "git_metadata_analysis_str": git_stats_str,
                "readme_info_str": readme_info
            }
            analysis_result = chain.invoke(llm_input)
            return analysis_result
        except Exception as e:
            print(f"GitAnalyzerAgent: LLM Git ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"summary": "Git í™œë™ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", "error": str(e)}

    def analyze_git(self, state: LangGraphState) -> LangGraphState:
        git_identifier = state.get("github_email", state.get("user_id"))
        print(f"GitAnalyzerAgent: ì‚¬ìš©ìž ì‹ë³„ìž '{git_identifier}' Git í™œë™ ë¶„ì„ ì‹œìž‘ (ë‚ ì§œ: {state.get('target_date')})...")
        
        user_name_for_context = state.get("user_name")
        target_date = state.get("target_date")
        wbs_data = state.get("wbs_data")

        analysis_result = {} # ê¸°ë³¸ê°’ ì´ˆê¸°í™”
        if not git_identifier:
            error_msg = "Git ë¶„ì„ìš© ì‹ë³„ìž(github_email/user_id) ëˆ„ë½"; print(f"GitAnalyzerAgent: {error_msg}")
            analysis_result = {"error": error_msg, "summary": "ì‚¬ìš©ìž ì‹ë³„ìž ëˆ„ë½"}
        elif not target_date: # Git í™œë™ì€ ë‚ ì§œ í•„í„°ë§ í•„ìˆ˜
            error_msg = "GitAnalyzerAgent: target_dateê°€ Stateì— ì œê³µë˜ì§€ ì•Šì•„ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤."
            print(error_msg)
            analysis_result = {"error": error_msg, "summary": "ëŒ€ìƒ ë‚ ì§œ ëˆ„ë½"}
        else:
            retrieved_dict = retrieve_git_activities(
                qdrant_client=self.qdrant_client, 
                git_author_identifier=git_identifier, 
                target_date_str=target_date
                # scroll_limitì€ retriever ë‚´ë¶€ ê¸°ë³¸ê°’ ì‚¬ìš© ë˜ëŠ” ì—¬ê¸°ì„œ ì§€ì •
            )
            
            # ë°˜í™˜ê°’ì´ íŠœí”Œì´ë¯€ë¡œ ë¶„ë¦¬
            git_activities, readme_info = retrieved_dict

            state["retrieved_git_activities"] = git_activities
            state["retrieved_readme_info"] = readme_info  # ðŸ‘ˆ README ì •ë³´ë„ ì €ìž¥

            analysis_result = self._analyze_git_internal(
                git_identifier, user_name_for_context, target_date, wbs_data, git_activities, readme_info
            )
        
        return {"git_analysis_result": analysis_result}

    def __call__(self, state: LangGraphState) -> LangGraphState:
        return self.analyze_git(state)
