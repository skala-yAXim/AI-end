# agents/teams_analyzer.py
import os
import sys
import json
from datetime import datetime, timezone
from typing import Dict, Any, Optional, List

from qdrant_client import QdrantClient
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import JsonOutputParser
from langchain.prompts import PromptTemplate

from core import config
from core.state_definition import LangGraphState
from tools.vector_db_retriever import retrieve_teams_posts

class TeamsAnalyzer:
    def __init__(self, qdrant_client: QdrantClient):
        self.qdrant_client = qdrant_client
            
        self.llm = ChatOpenAI(
            model=config.FAST_MODEL, temperature=0.2,
            max_tokens=2000, openai_api_key=config.OPENAI_API_KEY
        )
        # self.wbs_data_handler ì œê±°
        
        prompt_file_path = os.path.join(config.PROMPTS_BASE_DIR, "teams_analyzer_prompt.md")
        try:
            with open(prompt_file_path, "r", encoding="utf-8") as f: 
                prompt_template_str = f.read()
            # ì˜ˆìƒ í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜: {user_id}, {user_name}, {target_date}, {posts}, {wbs_data}
            self.prompt = PromptTemplate.from_template(prompt_template_str)
        except FileNotFoundError:
            print(f"TeamsAnalyzer: ì˜¤ë¥˜ - í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {prompt_file_path}")
            self.prompt_template_str = """
ì‚¬ìš©ìž ID {user_id} (ì´ë¦„: {user_name})ì˜ {target_date} Teams í™œë™ ë‚´ì—­({posts})ê³¼ WBS ì—…ë¬´({wbs_data})ë¥¼ ë¶„ì„í•˜ì—¬, 
ì£¼ìš” ëŒ€í™” ë‚´ìš© ìš”ì•½, ì—…ë¬´ ê´€ë ¨ì„±, WBS ìž‘ì—… ë§¤ì¹­ ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”.
"""
            self.prompt = PromptTemplate.from_template(self.prompt_template_str)
            
        self.parser = JsonOutputParser()

    def _prepare_teams_posts_for_llm(self, retrieved_posts_list: List[Dict], target_date_str: Optional[str]) -> str:
        date_info = f"({target_date_str} ê¸°ì¤€)" if target_date_str else "(ìµœê·¼ í™œë™ ê¸°ì¤€)"
        if not retrieved_posts_list: 
            return f"### Teams ê²Œì‹œë¬¼ ë°ì´í„° {date_info}:\në¶„ì„í•  Teams ê²Œì‹œë¬¼ì´ ì—†ìŠµë‹ˆë‹¤."
        
        # LLM ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ê³ ë ¤í•˜ì—¬ ìµœëŒ€ 30ê±´, ê° ê²Œì‹œë¬¼ ë‚´ìš©ë„ ì¼ë¶€ë§Œ
        parts = [f"### Teams ê²Œì‹œë¬¼ ë°ì´í„° {date_info} (ìµœëŒ€ {min(len(retrieved_posts_list), 30)}ê±´ í‘œì‹œ):"]
        for item in retrieved_posts_list[:30]: 
            meta = item.get("metadata", {})
            content = item.get("page_content", "")[:500] # ë‚´ìš© ì¼ë¶€
            # ì‹¤ì œ Teams ìž‘ì„±ìž ID í•„ë“œëª… (ì˜ˆ: user_id, author_id ë“±)
            author_display = meta.get("user_id", meta.get("author_name", meta.get("author_id", "ìµëª…"))) 
            timestamp = meta.get("date", "ì‹œê°„ ì •ë³´ ì—†ìŒ") # ì‹¤ì œ Qdrant í•„ë“œëª…: date
            channel = meta.get("channel_name", meta.get("channel", "ì•Œ ìˆ˜ ì—†ëŠ” ì±„ë„"))
            parts.append(f"- ìž‘ì„±ìž: {author_display}\n  ì±„ë„: {channel}\n  ì‹œê°„: {timestamp}\n  ë‚´ìš©: {content}...\n---")
        return "\n".join(parts)

    def _analyze_teams_data_internal(
            self, 
            user_id: str, # Teams ë¶„ì„ ëŒ€ìƒ user_id
            user_name: Optional[str], # LLM í”„ë¡¬í”„íŠ¸ìš© user_name 
            target_date: str, # target_dateëŠ” í•„ìˆ˜
            wbs_data: Optional[dict],
            project_name: Optional[str],
            project_description: Optional[str],
            project_period: Optional[str],
            retrieved_posts_list: List[Dict]
        ) -> Dict[str, Any]:
        print(f"TeamsAnalyzer: ì‚¬ìš©ìž ID '{user_id}'ì˜ Teams ê²Œì‹œë¬¼ {len(retrieved_posts_list)}ê°œ ë¶„ì„ ì‹œìž‘ (ëŒ€ìƒì¼: {target_date}).")

        if not retrieved_posts_list:
            print(f"TeamsAnalyzer: ì‚¬ìš©ìž ID '{user_id}'ì— ëŒ€í•œ ë¶„ì„í•  Teams ê²Œì‹œë¬¼ì´ ì—†ìŠµë‹ˆë‹¤ (ëŒ€ìƒì¼: {target_date}).")
            return {
                "user_id": user_id,
                "date": target_date,
                "type": "Teams",
                "total_tasks": 0,
                "teams_analysis": {
                    "matched_tasks": [],
                    "unmatched_tasks": [],
                    "daily_reflection": {
                        "title": "ðŸ” ì˜¤ëŠ˜ì˜ íšŒê³  ë° ê°œì„ ì ",
                        "content": "ë¶„ì„í•  Teams ê²Œì‹œë¬¼ì´ ì—†ì–´ ì—…ë¬´ í˜„í™©ì„ íŒŒì•…í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    }
                },
                "error": "No Teams posts to analyze"
            }

        wbs_data_str = json.dumps(wbs_data, ensure_ascii=False, indent=2) if wbs_data else "WBS ì •ë³´ ì—†ìŒ"
        posts_data_str = self._prepare_teams_posts_for_llm(retrieved_posts_list, target_date)

        chain = self.prompt | self.llm | self.parser
        
        try:
            llm_input = {
                "user_id": user_id,
                "user_name": user_name or user_id,
                "target_date": target_date,
                "posts": posts_data_str, # í”„ë¡¬í”„íŠ¸ì˜ {posts} ë³€ìˆ˜
                "wbs_data": wbs_data_str, # í”„ë¡¬í”„íŠ¸ì˜ {wbs_data} ë³€ìˆ˜
                "project_name": project_name,
                "project_description": project_description,
                "project_period": project_period
            }
            result = chain.invoke(llm_input)
            return result # LLM ìˆœìˆ˜ ê²°ê³¼ë§Œ ë°˜í™˜
        except Exception as e:
            print(f"TeamsAnalyzer: LLM Teams ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"summary": "Teams í™œë™ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", "error": str(e)}

    def analyze_teams(self, state: LangGraphState) -> LangGraphState:
        print(f"TeamsAnalyzer: ì‚¬ìš©ìž ID '{state.get('user_id')}' Teams í™œë™ ë¶„ì„ ì‹œìž‘ (ë‚ ì§œ: {state.get('target_date')})...")
        
        user_id = state.get("user_id")
        user_name = state.get("user_name")
        target_date = state.get("target_date")
        wbs_data = state.get("wbs_data")
        project_name = state.get("project_name")
        project_description = state.get("project_description")
        project_period = state.get("project_period")

        analysis_result = {} # ê¸°ë³¸ê°’ ì´ˆê¸°í™”
        if not user_id:
            error_msg = "TeamsAnalyzer: user_idê°€ Stateì— ì œê³µë˜ì§€ ì•Šì•„ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤."
            print(error_msg)
            analysis_result = {"error": error_msg, "summary": "ì‚¬ìš©ìž ID ëˆ„ë½"}
        elif not target_date: # TeamsëŠ” ë‚ ì§œ í•„í„°ë§ í•„ìˆ˜
            error_msg = "TeamsAnalyzer: target_dateê°€ Stateì— ì œê³µë˜ì§€ ì•Šì•„ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤."
            print(error_msg)
            analysis_result = {"error": error_msg, "summary": "ëŒ€ìƒ ë‚ ì§œ ëˆ„ë½"}
        else:
            retrieved_list = retrieve_teams_posts(
                qdrant_client=self.qdrant_client, 
                user_id=user_id, 
                target_date_str=target_date
                # scroll_limitì€ retriever ë‚´ë¶€ ê¸°ë³¸ê°’ ì‚¬ìš© ë˜ëŠ” ì—¬ê¸°ì„œ ì§€ì •
            )
            state["retrieved_teams_posts"] = retrieved_list # í•„ìš”ì‹œ ì €ìž¥

            analysis_result = self._analyze_teams_data_internal(
                user_id, user_name, target_date, wbs_data, project_name, project_description, project_period, retrieved_list
            )
        
        return {"teams_analysis_result": analysis_result}

    def __call__(self, state: LangGraphState) -> LangGraphState:
        return {"teams_analysis_result": self.analyze_teams(state)["teams_analysis_result"]}